{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06b61b-33cb-4fdd-a505-a22c6be9b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the goal of this notebook is to use 4 machine learning models:\n",
    "# logistic regression, Knn, random forest, Svm \n",
    "# to predict deepface race-classification errors and compare their performance the baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909ac78a-43cd-4cff-bab5-5de3083fb4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 12) (2100, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>pred_gender_score</th>\n",
       "      <th>pred_race</th>\n",
       "      <th>pred_race_score</th>\n",
       "      <th>error</th>\n",
       "      <th>file</th>\n",
       "      <th>race_true</th>\n",
       "      <th>gender_true</th>\n",
       "      <th>img_path</th>\n",
       "      <th>brightness</th>\n",
       "      <th>contrast</th>\n",
       "      <th>saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman</td>\n",
       "      <td>88.418669</td>\n",
       "      <td>black</td>\n",
       "      <td>43.714210</td>\n",
       "      <td>None</td>\n",
       "      <td>train/60423.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/60423.jpg</td>\n",
       "      <td>48.987080</td>\n",
       "      <td>59.403837</td>\n",
       "      <td>167.363665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man</td>\n",
       "      <td>97.433734</td>\n",
       "      <td>black</td>\n",
       "      <td>78.286773</td>\n",
       "      <td>None</td>\n",
       "      <td>train/45029.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/45029.jpg</td>\n",
       "      <td>141.144018</td>\n",
       "      <td>61.018735</td>\n",
       "      <td>126.112693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woman</td>\n",
       "      <td>99.483669</td>\n",
       "      <td>latino hispanic</td>\n",
       "      <td>41.124514</td>\n",
       "      <td>None</td>\n",
       "      <td>train/81730.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/81730.jpg</td>\n",
       "      <td>32.576097</td>\n",
       "      <td>43.355361</td>\n",
       "      <td>46.195073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man</td>\n",
       "      <td>89.559507</td>\n",
       "      <td>indian</td>\n",
       "      <td>58.377320</td>\n",
       "      <td>None</td>\n",
       "      <td>train/72069.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/72069.jpg</td>\n",
       "      <td>106.053985</td>\n",
       "      <td>67.849858</td>\n",
       "      <td>49.254235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man</td>\n",
       "      <td>64.608073</td>\n",
       "      <td>black</td>\n",
       "      <td>34.814405</td>\n",
       "      <td>None</td>\n",
       "      <td>train/37655.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/37655.jpg</td>\n",
       "      <td>55.268659</td>\n",
       "      <td>29.317591</td>\n",
       "      <td>129.966129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_gender  pred_gender_score        pred_race  pred_race_score error  \\\n",
       "0       Woman          88.418669            black        43.714210  None   \n",
       "1         Man          97.433734            black        78.286773  None   \n",
       "2       Woman          99.483669  latino hispanic        41.124514  None   \n",
       "3         Man          89.559507           indian        58.377320  None   \n",
       "4         Man          64.608073            black        34.814405  None   \n",
       "\n",
       "              file race_true gender_true  \\\n",
       "0  train/60423.jpg     Black      Female   \n",
       "1  train/45029.jpg     Black      Female   \n",
       "2  train/81730.jpg     Black      Female   \n",
       "3  train/72069.jpg     Black      Female   \n",
       "4  train/37655.jpg     Black      Female   \n",
       "\n",
       "                                            img_path  brightness   contrast  \\\n",
       "0  ../data/processed/balanced_images/train/60423.jpg   48.987080  59.403837   \n",
       "1  ../data/processed/balanced_images/train/45029.jpg  141.144018  61.018735   \n",
       "2  ../data/processed/balanced_images/train/81730.jpg   32.576097  43.355361   \n",
       "3  ../data/processed/balanced_images/train/72069.jpg  106.053985  67.849858   \n",
       "4  ../data/processed/balanced_images/train/37655.jpg   55.268659  29.317591   \n",
       "\n",
       "   saturation  \n",
       "0  167.363665  \n",
       "1  126.112693  \n",
       "2   46.195073  \n",
       "3   49.254235  \n",
       "4  129.966129  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "train = pd.read_parquet(\"../data/ml_ready/train_ml_ready.parquet\")\n",
    "val   = pd.read_parquet(\"../data/ml_ready/val_ml_ready.parquet\")\n",
    "\n",
    "print(train.shape, val.shape)\n",
    "train.head()\n",
    "# loading the feature datasets i built previously so i can train ML models on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96bbbc5-703e-45e1-8ba2-2bc38caa7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"race_true_clean\"] = train[\"race_true\"].str.lower().str.replace(\"_\", \" \")\n",
    "train[\"pred_race_clean\"] = train[\"pred_race\"].str.lower()\n",
    "\n",
    "val[\"race_true_clean\"] = val[\"race_true\"].str.lower().str.replace(\"_\", \" \")\n",
    "val[\"pred_race_clean\"] = val[\"pred_race\"].str.lower()\n",
    "\n",
    "y_train = (train[\"race_true_clean\"] != train[\"pred_race_clean\"]).astype(int)\n",
    "y_val   = (val[\"race_true_clean\"]   != val[\"pred_race_clean\"]).astype(int)\n",
    "\n",
    "feat_cols = [\"pred_race_score\", \"pred_gender_score\", \"brightness\", \"contrast\", \"saturation\"]\n",
    "\n",
    "X_train = train[feat_cols]\n",
    "X_val   = val[feat_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "# cleaning the labels and building the target 0 = correct, 1 = error\n",
    "# then selecting and scaling the numeric features for all future ML models\n",
    "\n",
    "# Nb: to make sure accuracy and the other metrics actually reflect the modelâ€™s ability to detect deepface errors \n",
    "# i defined the ML target here as 1 = error and 0 = correct.\n",
    "# notebook 3 used the opposite convention but only for descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55539a98-36c1-4036-82a6-cca026a99e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09dda0a-fcfa-42f8-90dc-cb1caf5ba02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic acc: 0.6671428571428571\n",
      "class balance val: [ 698 1402]\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=300)\n",
    "\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "log_pred = log_model.predict(X_val_scaled)\n",
    "print(\"logistic acc:\", accuracy_score(y_val, log_pred))\n",
    "print(\"class balance val:\", np.bincount(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83407aad-181f-4aca-ab8f-bfe269624d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2440 4560]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40245bb6-a6ed-42b8-9239-a43efc39ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the logistic regression achieves 67,% accuracy but this is misleading: \n",
    "# the dataset has 67% errors (majority class) so the model is essentially \n",
    "# learning to always predict \"error\" without capturing meaningful patterns.\n",
    "\n",
    "# this suggests that with current features, simple linear models cannot\n",
    "# reliably distinguish between correct and incorrect deepface predictions\n",
    "\n",
    "# either the features may not contain strong predictive signals\n",
    "# either the problem requires more complex feature engineering or non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766f070d-47f4-4b8a-9155-c8cc2e1d097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy if i always predcit 'error': 0.6676190476190477\n"
     ]
    }
   ],
   "source": [
    "#proof: \n",
    "naive_predictions = np.ones(len(y_val)) \n",
    "naive_accuracy = accuracy_score(y_val, naive_predictions)\n",
    "print(f\"accuracy if i always predcit 'error': {naive_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8cf8a6-e232-4a92-984b-0414181c9f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
