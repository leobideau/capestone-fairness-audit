{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406c7a6-59c8-4b3e-ab2e-7dd2b6ceeb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the goal here is to :\n",
    "# extract simple image features: brightness, contrast nd saturation\n",
    "# merge them with the deepface predictions from notebook 3\n",
    "# at the end save a clean dataset that i will use for the ml model in notebook 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e37039-eac0-413f-bac8-1e57b28368e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 8) (2100, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>pred_gender_score</th>\n",
       "      <th>pred_race</th>\n",
       "      <th>pred_race_score</th>\n",
       "      <th>error</th>\n",
       "      <th>file</th>\n",
       "      <th>race_true</th>\n",
       "      <th>gender_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman</td>\n",
       "      <td>88.418669</td>\n",
       "      <td>black</td>\n",
       "      <td>43.714210</td>\n",
       "      <td>None</td>\n",
       "      <td>train/60423.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man</td>\n",
       "      <td>97.433734</td>\n",
       "      <td>black</td>\n",
       "      <td>78.286773</td>\n",
       "      <td>None</td>\n",
       "      <td>train/45029.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woman</td>\n",
       "      <td>99.483669</td>\n",
       "      <td>latino hispanic</td>\n",
       "      <td>41.124514</td>\n",
       "      <td>None</td>\n",
       "      <td>train/81730.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man</td>\n",
       "      <td>89.559507</td>\n",
       "      <td>indian</td>\n",
       "      <td>58.377320</td>\n",
       "      <td>None</td>\n",
       "      <td>train/72069.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man</td>\n",
       "      <td>64.608073</td>\n",
       "      <td>black</td>\n",
       "      <td>34.814405</td>\n",
       "      <td>None</td>\n",
       "      <td>train/37655.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_gender  pred_gender_score        pred_race  pred_race_score error  \\\n",
       "0       Woman          88.418669            black        43.714210  None   \n",
       "1         Man          97.433734            black        78.286773  None   \n",
       "2       Woman          99.483669  latino hispanic        41.124514  None   \n",
       "3         Man          89.559507           indian        58.377320  None   \n",
       "4         Man          64.608073            black        34.814405  None   \n",
       "\n",
       "              file race_true gender_true  \n",
       "0  train/60423.jpg     Black      Female  \n",
       "1  train/45029.jpg     Black      Female  \n",
       "2  train/81730.jpg     Black      Female  \n",
       "3  train/72069.jpg     Black      Female  \n",
       "4  train/37655.jpg     Black      Female  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "root = \"..\"\n",
    "\n",
    "train_pred_path = os.path.join(root, \"results\", \"baseline\", \"pred_train.parquet\")\n",
    "val_pred_path   = os.path.join(root, \"results\", \"baseline\", \"pred_val.parquet\")\n",
    "\n",
    "train_pred = pd.read_parquet(train_pred_path)\n",
    "val_pred   = pd.read_parquet(val_pred_path)\n",
    "\n",
    "print(train_pred.shape, val_pred.shape)\n",
    "train_pred.head()\n",
    "# i load the deepface prediction files from notebook 3 so i can attach my own image features on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd0412d-4c74-4ef5-b60e-38c203f8ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            return {\"brightness\": None, \"contrast\": None, \"saturation\": None}\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        hsv  = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        brightness = gray.mean()\n",
    "        contrast   = gray.std()\n",
    "        saturation = hsv[:, :, 1].mean()\n",
    "\n",
    "        return {\n",
    "            \"brightness\": float(brightness),\n",
    "            \"contrast\": float(contrast),\n",
    "            \"saturation\": float(saturation),\n",
    "        }\n",
    "    except:\n",
    "        return {\"brightness\": None, \"contrast\": None, \"saturation\": None}\n",
    "# this function extracts simple image stats: i want to test if deepface fails more on dark or low contrast pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa50c2c-b730-4b5f-9fef-27ca853045ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>pred_gender_score</th>\n",
       "      <th>pred_race</th>\n",
       "      <th>pred_race_score</th>\n",
       "      <th>error</th>\n",
       "      <th>file</th>\n",
       "      <th>race_true</th>\n",
       "      <th>gender_true</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman</td>\n",
       "      <td>88.418669</td>\n",
       "      <td>black</td>\n",
       "      <td>43.714210</td>\n",
       "      <td>None</td>\n",
       "      <td>train/60423.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/60423.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man</td>\n",
       "      <td>97.433734</td>\n",
       "      <td>black</td>\n",
       "      <td>78.286773</td>\n",
       "      <td>None</td>\n",
       "      <td>train/45029.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/45029.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woman</td>\n",
       "      <td>99.483669</td>\n",
       "      <td>latino hispanic</td>\n",
       "      <td>41.124514</td>\n",
       "      <td>None</td>\n",
       "      <td>train/81730.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/81730.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_gender  pred_gender_score        pred_race  pred_race_score error  \\\n",
       "0       Woman          88.418669            black        43.714210  None   \n",
       "1         Man          97.433734            black        78.286773  None   \n",
       "2       Woman          99.483669  latino hispanic        41.124514  None   \n",
       "\n",
       "              file race_true gender_true  \\\n",
       "0  train/60423.jpg     Black      Female   \n",
       "1  train/45029.jpg     Black      Female   \n",
       "2  train/81730.jpg     Black      Female   \n",
       "\n",
       "                                            img_path  \n",
       "0  ../data/processed/balanced_images/train/60423.jpg  \n",
       "1  ../data/processed/balanced_images/train/45029.jpg  \n",
       "2  ../data/processed/balanced_images/train/81730.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_img_path(df, root):\n",
    "    df = df.copy()\n",
    "    df[\"img_path\"] = df[\"file\"].apply(\n",
    "        lambda f: os.path.join(root, \"data\", \"processed\", \"balanced_images\", \n",
    "                               \"train\" if \"train\" in f else \"val\", \n",
    "                               os.path.basename(f))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_pred = add_img_path(train_pred, root)\n",
    "val_pred   = add_img_path(val_pred, root)\n",
    "\n",
    "train_pred.head(3)\n",
    "# rebuilt the correct path to each image so i can extract pixels in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361a9d58-469c-4bfb-ac7d-4ab7cce58ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7000/7000 [00:06<00:00, 1130.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2100/2100 [00:01<00:00, 1140.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brightness</th>\n",
       "      <th>contrast</th>\n",
       "      <th>saturation</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.987080</td>\n",
       "      <td>59.403837</td>\n",
       "      <td>167.363665</td>\n",
       "      <td>train/60423.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141.144018</td>\n",
       "      <td>61.018735</td>\n",
       "      <td>126.112693</td>\n",
       "      <td>train/45029.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.576097</td>\n",
       "      <td>43.355361</td>\n",
       "      <td>46.195073</td>\n",
       "      <td>train/81730.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.053985</td>\n",
       "      <td>67.849858</td>\n",
       "      <td>49.254235</td>\n",
       "      <td>train/72069.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.268659</td>\n",
       "      <td>29.317591</td>\n",
       "      <td>129.966129</td>\n",
       "      <td>train/37655.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brightness   contrast  saturation             file\n",
       "0   48.987080  59.403837  167.363665  train/60423.jpg\n",
       "1  141.144018  61.018735  126.112693  train/45029.jpg\n",
       "2   32.576097  43.355361   46.195073  train/81730.jpg\n",
       "3  106.053985  67.849858   49.254235  train/72069.jpg\n",
       "4   55.268659  29.317591  129.966129  train/37655.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_features(df):\n",
    "    rows = []\n",
    "    for r in tqdm(df.itertuples(), total=len(df)):\n",
    "        feats = extract_features(r.img_path)\n",
    "        feats[\"file\"] = r.file\n",
    "        rows.append(feats)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_feats = compute_features(train_pred)\n",
    "val_feats   = compute_features(val_pred)\n",
    "\n",
    "train_feats.head()\n",
    "# here i'm extracting brightness contrast saturation for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aaf7b96-cd13-45df-b044-dadde823e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 4), (2100, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = os.path.join(root, \"results\", \"features\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "train_feats_path = os.path.join(out_dir, \"train_features.parquet\")\n",
    "val_feats_path   = os.path.join(out_dir, \"val_features.parquet\")\n",
    "\n",
    "train_feats.to_parquet(train_feats_path, index=False)\n",
    "val_feats.to_parquet(val_feats_path, index=False)\n",
    "\n",
    "train_feats.shape, val_feats.shape\n",
    "# saving the extracted features so i can reuse it later without recomputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e634f893-7b20-4978-88c6-5387395cc613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_gender</th>\n",
       "      <th>pred_gender_score</th>\n",
       "      <th>pred_race</th>\n",
       "      <th>pred_race_score</th>\n",
       "      <th>error</th>\n",
       "      <th>file</th>\n",
       "      <th>race_true</th>\n",
       "      <th>gender_true</th>\n",
       "      <th>img_path</th>\n",
       "      <th>brightness</th>\n",
       "      <th>contrast</th>\n",
       "      <th>saturation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman</td>\n",
       "      <td>88.418669</td>\n",
       "      <td>black</td>\n",
       "      <td>43.714210</td>\n",
       "      <td>None</td>\n",
       "      <td>train/60423.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/60423.jpg</td>\n",
       "      <td>48.987080</td>\n",
       "      <td>59.403837</td>\n",
       "      <td>167.363665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man</td>\n",
       "      <td>97.433734</td>\n",
       "      <td>black</td>\n",
       "      <td>78.286773</td>\n",
       "      <td>None</td>\n",
       "      <td>train/45029.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/45029.jpg</td>\n",
       "      <td>141.144018</td>\n",
       "      <td>61.018735</td>\n",
       "      <td>126.112693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woman</td>\n",
       "      <td>99.483669</td>\n",
       "      <td>latino hispanic</td>\n",
       "      <td>41.124514</td>\n",
       "      <td>None</td>\n",
       "      <td>train/81730.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/81730.jpg</td>\n",
       "      <td>32.576097</td>\n",
       "      <td>43.355361</td>\n",
       "      <td>46.195073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man</td>\n",
       "      <td>89.559507</td>\n",
       "      <td>indian</td>\n",
       "      <td>58.377320</td>\n",
       "      <td>None</td>\n",
       "      <td>train/72069.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/72069.jpg</td>\n",
       "      <td>106.053985</td>\n",
       "      <td>67.849858</td>\n",
       "      <td>49.254235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man</td>\n",
       "      <td>64.608073</td>\n",
       "      <td>black</td>\n",
       "      <td>34.814405</td>\n",
       "      <td>None</td>\n",
       "      <td>train/37655.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>../data/processed/balanced_images/train/37655.jpg</td>\n",
       "      <td>55.268659</td>\n",
       "      <td>29.317591</td>\n",
       "      <td>129.966129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_gender  pred_gender_score        pred_race  pred_race_score error  \\\n",
       "0       Woman          88.418669            black        43.714210  None   \n",
       "1         Man          97.433734            black        78.286773  None   \n",
       "2       Woman          99.483669  latino hispanic        41.124514  None   \n",
       "3         Man          89.559507           indian        58.377320  None   \n",
       "4         Man          64.608073            black        34.814405  None   \n",
       "\n",
       "              file race_true gender_true  \\\n",
       "0  train/60423.jpg     Black      Female   \n",
       "1  train/45029.jpg     Black      Female   \n",
       "2  train/81730.jpg     Black      Female   \n",
       "3  train/72069.jpg     Black      Female   \n",
       "4  train/37655.jpg     Black      Female   \n",
       "\n",
       "                                            img_path  brightness   contrast  \\\n",
       "0  ../data/processed/balanced_images/train/60423.jpg   48.987080  59.403837   \n",
       "1  ../data/processed/balanced_images/train/45029.jpg  141.144018  61.018735   \n",
       "2  ../data/processed/balanced_images/train/81730.jpg   32.576097  43.355361   \n",
       "3  ../data/processed/balanced_images/train/72069.jpg  106.053985  67.849858   \n",
       "4  ../data/processed/balanced_images/train/37655.jpg   55.268659  29.317591   \n",
       "\n",
       "   saturation  \n",
       "0  167.363665  \n",
       "1  126.112693  \n",
       "2   46.195073  \n",
       "3   49.254235  \n",
       "4  129.966129  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full = train_pred.merge(train_feats, on=\"file\", how=\"left\")\n",
    "val_full   = val_pred.merge(val_feats, on=\"file\", how=\"left\")\n",
    "\n",
    "train_full.head()\n",
    "# by combining deepface outputs + my image features i'll have a clean dataset ready for ML part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88279ef-25a2-44ad-9211-8348205e5092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "ml_dir = os.path.join(root, \"data\", \"ml_ready\")\n",
    "os.makedirs(ml_dir, exist_ok=True)\n",
    "\n",
    "train_full.to_parquet(os.path.join(ml_dir, \"train_ml_ready.parquet\"), index=False)\n",
    "val_full.to_parquet(os.path.join(ml_dir, \"val_ml_ready.parquet\"), index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c032f-9fb6-4f76-8514-f287ba2795a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dataset ready for notebook 5 where i will train the model that predicts deepface errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
