<style type="text/css">
#T_b169b_row0_col3, #T_b169b_row1_col3, #T_b169b_row17_col3 {
  background-color: #40bd72;
  color: #f1f1f1;
}
#T_b169b_row0_col4, #T_b169b_row8_col5, #T_b169b_row17_col4, #T_b169b_row27_col4 {
  background-color: #b0dd2f;
  color: #000000;
}
#T_b169b_row0_col5, #T_b169b_row1_col5, #T_b169b_row5_col4, #T_b169b_row17_col5, #T_b169b_row27_col5 {
  background-color: #1fa187;
  color: #f1f1f1;
}
#T_b169b_row0_col6, #T_b169b_row8_col3, #T_b169b_row17_col6, #T_b169b_row22_col5, #T_b169b_row31_col4, #T_b169b_row31_col7 {
  background-color: #fde725;
  color: #000000;
}
#T_b169b_row0_col7, #T_b169b_row7_col3, #T_b169b_row7_col4, #T_b169b_row7_col5, #T_b169b_row7_col6, #T_b169b_row23_col6 {
  background-color: #440154;
  color: #f1f1f1;
}
#T_b169b_row1_col4, #T_b169b_row13_col5 {
  background-color: #addc30;
  color: #000000;
}
#T_b169b_row1_col6 {
  background-color: #f8e621;
  color: #000000;
}
#T_b169b_row1_col7 {
  background-color: #2b758e;
  color: #f1f1f1;
}
#T_b169b_row2_col3 {
  background-color: #3bbb75;
  color: #f1f1f1;
}
#T_b169b_row2_col4, #T_b169b_row30_col5 {
  background-color: #a2da37;
  color: #000000;
}
#T_b169b_row2_col5, #T_b169b_row29_col6 {
  background-color: #20a386;
  color: #f1f1f1;
}
#T_b169b_row2_col6, #T_b169b_row11_col7, #T_b169b_row13_col7, #T_b169b_row19_col3, #T_b169b_row22_col7 {
  background-color: #d0e11c;
  color: #000000;
}
#T_b169b_row2_col7 {
  background-color: #31668e;
  color: #f1f1f1;
}
#T_b169b_row3_col3 {
  background-color: #50c46a;
  color: #000000;
}
#T_b169b_row3_col4, #T_b169b_row9_col5 {
  background-color: #93d741;
  color: #000000;
}
#T_b169b_row3_col5 {
  background-color: #32b67a;
  color: #f1f1f1;
}
#T_b169b_row3_col6, #T_b169b_row18_col5, #T_b169b_row22_col4 {
  background-color: #44bf70;
  color: #f1f1f1;
}
#T_b169b_row3_col7 {
  background-color: #27808e;
  color: #f1f1f1;
}
#T_b169b_row4_col3 {
  background-color: #228b8d;
  color: #f1f1f1;
}
#T_b169b_row4_col4 {
  background-color: #27ad81;
  color: #f1f1f1;
}
#T_b169b_row4_col5, #T_b169b_row5_col5, #T_b169b_row6_col5 {
  background-color: #20a486;
  color: #f1f1f1;
}
#T_b169b_row4_col6 {
  background-color: #2f6b8e;
  color: #f1f1f1;
}
#T_b169b_row4_col7 {
  background-color: #414487;
  color: #f1f1f1;
}
#T_b169b_row5_col3 {
  background-color: #26828e;
  color: #f1f1f1;
}
#T_b169b_row5_col6 {
  background-color: #3b518b;
  color: #f1f1f1;
}
#T_b169b_row5_col7 {
  background-color: #443a83;
  color: #f1f1f1;
}
#T_b169b_row6_col3 {
  background-color: #29798e;
  color: #f1f1f1;
}
#T_b169b_row6_col4 {
  background-color: #1f958b;
  color: #f1f1f1;
}
#T_b169b_row6_col6 {
  background-color: #463480;
  color: #f1f1f1;
}
#T_b169b_row6_col7, #T_b169b_row7_col7 {
  background-color: #423f85;
  color: #f1f1f1;
}
#T_b169b_row8_col4, #T_b169b_row28_col5, #T_b169b_row32_col3 {
  background-color: #f6e620;
  color: #000000;
}
#T_b169b_row8_col6, #T_b169b_row13_col6 {
  background-color: #31b57b;
  color: #f1f1f1;
}
#T_b169b_row8_col7, #T_b169b_row11_col3, #T_b169b_row11_col4, #T_b169b_row21_col7 {
  background-color: #cae11f;
  color: #000000;
}
#T_b169b_row9_col3, #T_b169b_row10_col4, #T_b169b_row16_col4, #T_b169b_row16_col7, #T_b169b_row25_col4, #T_b169b_row25_col7 {
  background-color: #d5e21a;
  color: #000000;
}
#T_b169b_row9_col4, #T_b169b_row10_col3, #T_b169b_row16_col3, #T_b169b_row25_col3 {
  background-color: #dae319;
  color: #000000;
}
#T_b169b_row9_col6 {
  background-color: #2ab07f;
  color: #f1f1f1;
}
#T_b169b_row9_col7, #T_b169b_row15_col4 {
  background-color: #e7e419;
  color: #000000;
}
#T_b169b_row10_col5, #T_b169b_row12_col4, #T_b169b_row16_col5, #T_b169b_row18_col4, #T_b169b_row20_col4, #T_b169b_row25_col5 {
  background-color: #aadc32;
  color: #000000;
}
#T_b169b_row10_col6, #T_b169b_row25_col6 {
  background-color: #1fa088;
  color: #f1f1f1;
}
#T_b169b_row10_col7, #T_b169b_row23_col7, #T_b169b_row32_col7 {
  background-color: #d8e219;
  color: #000000;
}
#T_b169b_row11_col5 {
  background-color: #a5db36;
  color: #000000;
}
#T_b169b_row11_col6 {
  background-color: #1f9a8a;
  color: #f1f1f1;
}
#T_b169b_row12_col3, #T_b169b_row20_col3 {
  background-color: #90d743;
  color: #000000;
}
#T_b169b_row12_col5, #T_b169b_row12_col7, #T_b169b_row20_col5, #T_b169b_row20_col7, #T_b169b_row22_col3 {
  background-color: #6ece58;
  color: #000000;
}
#T_b169b_row12_col6, #T_b169b_row20_col6 {
  background-color: #1fa287;
  color: #f1f1f1;
}
#T_b169b_row13_col3, #T_b169b_row27_col6, #T_b169b_row30_col7 {
  background-color: #fbe723;
  color: #000000;
}
#T_b169b_row13_col4, #T_b169b_row15_col3, #T_b169b_row21_col5, #T_b169b_row31_col3 {
  background-color: #f4e61e;
  color: #000000;
}
#T_b169b_row14_col3 {
  background-color: #c8e020;
  color: #000000;
}
#T_b169b_row14_col4, #T_b169b_row29_col3 {
  background-color: #eae51a;
  color: #000000;
}
#T_b169b_row14_col5, #T_b169b_row26_col5 {
  background-color: #65cb5e;
  color: #000000;
}
#T_b169b_row14_col6 {
  background-color: #7cd250;
  color: #000000;
}
#T_b169b_row14_col7, #T_b169b_row24_col6, #T_b169b_row29_col4, #T_b169b_row30_col4 {
  background-color: #dfe318;
  color: #000000;
}
#T_b169b_row15_col5 {
  background-color: #bade28;
  color: #000000;
}
#T_b169b_row15_col6 {
  background-color: #21a585;
  color: #f1f1f1;
}
#T_b169b_row15_col7, #T_b169b_row19_col5 {
  background-color: #bddf26;
  color: #000000;
}
#T_b169b_row16_col6 {
  background-color: #1fa188;
  color: #f1f1f1;
}
#T_b169b_row17_col7, #T_b169b_row26_col4, #T_b169b_row27_col7 {
  background-color: #d2e21b;
  color: #000000;
}
#T_b169b_row18_col3 {
  background-color: #73d056;
  color: #000000;
}
#T_b169b_row18_col6, #T_b169b_row24_col5, #T_b169b_row27_col3 {
  background-color: #42be71;
  color: #f1f1f1;
}
#T_b169b_row18_col7 {
  background-color: #75d054;
  color: #000000;
}
#T_b169b_row19_col4 {
  background-color: #c2df23;
  color: #000000;
}
#T_b169b_row19_col6 {
  background-color: #238a8d;
  color: #f1f1f1;
}
#T_b169b_row19_col7, #T_b169b_row24_col4 {
  background-color: #ece51b;
  color: #000000;
}
#T_b169b_row21_col3 {
  background-color: #6ccd5a;
  color: #000000;
}
#T_b169b_row21_col4 {
  background-color: #46c06f;
  color: #f1f1f1;
}
#T_b169b_row21_col6 {
  background-color: #471365;
  color: #f1f1f1;
}
#T_b169b_row22_col6 {
  background-color: #460b5e;
  color: #f1f1f1;
}
#T_b169b_row23_col3 {
  background-color: #58c765;
  color: #000000;
}
#T_b169b_row23_col4 {
  background-color: #35b779;
  color: #f1f1f1;
}
#T_b169b_row23_col5, #T_b169b_row29_col7, #T_b169b_row32_col4 {
  background-color: #efe51c;
  color: #000000;
}
#T_b169b_row24_col3, #T_b169b_row26_col3, #T_b169b_row29_col5, #T_b169b_row32_col5 {
  background-color: #b2dd2d;
  color: #000000;
}
#T_b169b_row24_col7 {
  background-color: #e5e419;
  color: #000000;
}
#T_b169b_row26_col6 {
  background-color: #52c569;
  color: #000000;
}
#T_b169b_row26_col7, #T_b169b_row28_col3 {
  background-color: #70cf57;
  color: #000000;
}
#T_b169b_row28_col4 {
  background-color: #4ac16d;
  color: #000000;
}
#T_b169b_row28_col6 {
  background-color: #481668;
  color: #f1f1f1;
}
#T_b169b_row28_col7 {
  background-color: #cde11d;
  color: #000000;
}
#T_b169b_row30_col3 {
  background-color: #e2e418;
  color: #000000;
}
#T_b169b_row30_col6 {
  background-color: #24aa83;
  color: #f1f1f1;
}
#T_b169b_row31_col5 {
  background-color: #81d34d;
  color: #000000;
}
#T_b169b_row31_col6 {
  background-color: #77d153;
  color: #000000;
}
#T_b169b_row32_col6 {
  background-color: #26ad81;
  color: #f1f1f1;
}
</style>
<table id="T_b169b">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_b169b_level0_col0" class="col_heading level0 col0" >family_order</th>
      <th id="T_b169b_level0_col1" class="col_heading level0 col1" >family</th>
      <th id="T_b169b_level0_col2" class="col_heading level0 col2" >model</th>
      <th id="T_b169b_level0_col3" class="col_heading level0 col3" >accuracy</th>
      <th id="T_b169b_level0_col4" class="col_heading level0 col4" >f1_score</th>
      <th id="T_b169b_level0_col5" class="col_heading level0 col5" >precision</th>
      <th id="T_b169b_level0_col6" class="col_heading level0 col6" >recall</th>
      <th id="T_b169b_level0_col7" class="col_heading level0 col7" >roc_auc</th>
      <th id="T_b169b_level0_col8" class="col_heading level0 col8" >comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_b169b_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_b169b_row0_col0" class="data row0 col0" >0</td>
      <td id="T_b169b_row0_col1" class="data row0 col1" >no embeddings</td>
      <td id="T_b169b_row0_col2" class="data row0 col2" >no embeddings svm linear</td>
      <td id="T_b169b_row0_col3" class="data row0 col3" >0.6676</td>
      <td id="T_b169b_row0_col4" class="data row0 col4" >0.8007</td>
      <td id="T_b169b_row0_col5" class="data row0 col5" >0.6676</td>
      <td id="T_b169b_row0_col6" class="data row0 col6" >1.0000</td>
      <td id="T_b169b_row0_col7" class="data row0 col7" >0.4596</td>
      <td id="T_b169b_row0_col8" class="data row0 col8" >predicts only class 1</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_b169b_row1_col0" class="data row1 col0" >0</td>
      <td id="T_b169b_row1_col1" class="data row1 col1" >no embeddings</td>
      <td id="T_b169b_row1_col2" class="data row1 col2" >no embeddings logistic regression</td>
      <td id="T_b169b_row1_col3" class="data row1 col3" >0.6671</td>
      <td id="T_b169b_row1_col4" class="data row1 col4" >0.7999</td>
      <td id="T_b169b_row1_col5" class="data row1 col5" >0.6681</td>
      <td id="T_b169b_row1_col6" class="data row1 col6" >0.9964</td>
      <td id="T_b169b_row1_col7" class="data row1 col7" >0.5877</td>
      <td id="T_b169b_row1_col8" class="data row1 col8" >baseline features, no learning</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_b169b_row2_col0" class="data row2 col0" >0</td>
      <td id="T_b169b_row2_col1" class="data row2 col1" >no embeddings</td>
      <td id="T_b169b_row2_col2" class="data row2 col2" >no embeddings svm rbf</td>
      <td id="T_b169b_row2_col3" class="data row2 col3" >0.6638</td>
      <td id="T_b169b_row2_col4" class="data row2 col4" >0.7951</td>
      <td id="T_b169b_row2_col5" class="data row2 col5" >0.6703</td>
      <td id="T_b169b_row2_col6" class="data row2 col6" >0.9772</td>
      <td id="T_b169b_row2_col7" class="data row2 col7" >0.5672</td>
      <td id="T_b169b_row2_col8" class="data row2 col8" >weak recall</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_b169b_row3_col0" class="data row3 col0" >0</td>
      <td id="T_b169b_row3_col1" class="data row3 col1" >no embeddings</td>
      <td id="T_b169b_row3_col2" class="data row3 col2" >no embeddings random forest</td>
      <td id="T_b169b_row3_col3" class="data row3 col3" >0.6762</td>
      <td id="T_b169b_row3_col4" class="data row3 col4" >0.7886</td>
      <td id="T_b169b_row3_col5" class="data row3 col5" >0.6990</td>
      <td id="T_b169b_row3_col6" class="data row3 col6" >0.9044</td>
      <td id="T_b169b_row3_col7" class="data row3 col7" >0.6016</td>
      <td id="T_b169b_row3_col8" class="data row3 col8" >slightly better, still weak</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_b169b_row4_col0" class="data row4 col0" >0</td>
      <td id="T_b169b_row4_col1" class="data row4 col1" >no embeddings</td>
      <td id="T_b169b_row4_col2" class="data row4 col2" >no embeddings knn k=7</td>
      <td id="T_b169b_row4_col3" class="data row4 col3" >0.6033</td>
      <td id="T_b169b_row4_col4" class="data row4 col4" >0.7268</td>
      <td id="T_b169b_row4_col5" class="data row4 col5" >0.6727</td>
      <td id="T_b169b_row4_col6" class="data row4 col6" >0.7903</td>
      <td id="T_b169b_row4_col7" class="data row4 col7" >0.5260</td>
      <td id="T_b169b_row4_col8" class="data row4 col8" >best knn baseline, still poor</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_b169b_row5_col0" class="data row5 col0" >0</td>
      <td id="T_b169b_row5_col1" class="data row5 col1" >no embeddings</td>
      <td id="T_b169b_row5_col2" class="data row5 col2" >no embeddings knn k=5</td>
      <td id="T_b169b_row5_col3" class="data row5 col3" >0.5919</td>
      <td id="T_b169b_row5_col4" class="data row5 col4" >0.7129</td>
      <td id="T_b169b_row5_col5" class="data row5 col5" >0.6721</td>
      <td id="T_b169b_row5_col6" class="data row5 col6" >0.7589</td>
      <td id="T_b169b_row5_col7" class="data row5 col7" >0.5161</td>
      <td id="T_b169b_row5_col8" class="data row5 col8" >slight improvement, still weak</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_b169b_row6_col0" class="data row6 col0" >0</td>
      <td id="T_b169b_row6_col1" class="data row6 col1" >no embeddings</td>
      <td id="T_b169b_row6_col2" class="data row6 col2" >no embeddings knn k=3</td>
      <td id="T_b169b_row6_col3" class="data row6 col3" >0.5814</td>
      <td id="T_b169b_row6_col4" class="data row6 col4" >0.6987</td>
      <td id="T_b169b_row6_col5" class="data row6 col5" >0.6726</td>
      <td id="T_b169b_row6_col6" class="data row6 col6" >0.7268</td>
      <td id="T_b169b_row6_col7" class="data row6 col7" >0.5212</td>
      <td id="T_b169b_row6_col8" class="data row6 col8" >weak model, unstable</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_b169b_row7_col0" class="data row7 col0" >0</td>
      <td id="T_b169b_row7_col1" class="data row7 col1" >no embeddings</td>
      <td id="T_b169b_row7_col2" class="data row7 col2" >deepface baseline</td>
      <td id="T_b169b_row7_col3" class="data row7 col3" >0.4619</td>
      <td id="T_b169b_row7_col4" class="data row7 col4" >0.5500</td>
      <td id="T_b169b_row7_col5" class="data row7 col5" >0.4619</td>
      <td id="T_b169b_row7_col6" class="data row7 col6" >0.6800</td>
      <td id="T_b169b_row7_col7" class="data row7 col7" >0.5200</td>
      <td id="T_b169b_row7_col8" class="data row7 col8" >DeepFace original model (0% on Southeast Asian)</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_b169b_row8_col0" class="data row8 col0" >1</td>
      <td id="T_b169b_row8_col1" class="data row8 col1" >embeddings</td>
      <td id="T_b169b_row8_col2" class="data row8 col2" >svm linear</td>
      <td id="T_b169b_row8_col3" class="data row8 col3" >0.7581</td>
      <td id="T_b169b_row8_col4" class="data row8 col4" >0.8308</td>
      <td id="T_b169b_row8_col5" class="data row8 col5" >0.7794</td>
      <td id="T_b169b_row8_col6" class="data row8 col6" >0.8894</td>
      <td id="T_b169b_row8_col7" class="data row8 col7" >0.7622</td>
      <td id="T_b169b_row8_col8" class="data row8 col8" >best classical model</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_b169b_row9_col0" class="data row9 col0" >1</td>
      <td id="T_b169b_row9_col1" class="data row9 col1" >embeddings</td>
      <td id="T_b169b_row9_col2" class="data row9 col2" >random forest</td>
      <td id="T_b169b_row9_col3" class="data row9 col3" >0.7386</td>
      <td id="T_b169b_row9_col4" class="data row9 col4" >0.8184</td>
      <td id="T_b169b_row9_col5" class="data row9 col5" >0.7631</td>
      <td id="T_b169b_row9_col6" class="data row9 col6" >0.8823</td>
      <td id="T_b169b_row9_col7" class="data row9 col7" >0.7763</td>
      <td id="T_b169b_row9_col8" class="data row9 col8" >good overall boost</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_b169b_row10_col0" class="data row10 col0" >1</td>
      <td id="T_b169b_row10_col1" class="data row10 col1" >embeddings</td>
      <td id="T_b169b_row10_col2" class="data row10 col2" >logistic regression</td>
      <td id="T_b169b_row10_col3" class="data row10 col3" >0.7410</td>
      <td id="T_b169b_row10_col4" class="data row10 col4" >0.8160</td>
      <td id="T_b169b_row10_col5" class="data row10 col5" >0.7761</td>
      <td id="T_b169b_row10_col6" class="data row10 col6" >0.8602</td>
      <td id="T_b169b_row10_col7" class="data row10 col7" >0.7681</td>
      <td id="T_b169b_row10_col8" class="data row10 col8" >embeddings give strong boost</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_b169b_row11_col0" class="data row11 col0" >1</td>
      <td id="T_b169b_row11_col1" class="data row11 col1" >embeddings</td>
      <td id="T_b169b_row11_col2" class="data row11 col2" >svm rbf</td>
      <td id="T_b169b_row11_col3" class="data row11 col3" >0.7348</td>
      <td id="T_b169b_row11_col4" class="data row11 col4" >0.8111</td>
      <td id="T_b169b_row11_col5" class="data row11 col5" >0.7731</td>
      <td id="T_b169b_row11_col6" class="data row11 col6" >0.8531</td>
      <td id="T_b169b_row11_col7" class="data row11 col7" >0.7650</td>
      <td id="T_b169b_row11_col8" class="data row11 col8" >weaker than linear</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_b169b_row12_col0" class="data row12 col0" >1</td>
      <td id="T_b169b_row12_col1" class="data row12 col1" >embeddings</td>
      <td id="T_b169b_row12_col2" class="data row12 col2" >knn k=7</td>
      <td id="T_b169b_row12_col3" class="data row12 col3" >0.7095</td>
      <td id="T_b169b_row12_col4" class="data row12 col4" >0.7988</td>
      <td id="T_b169b_row12_col5" class="data row12 col5" >0.7429</td>
      <td id="T_b169b_row12_col6" class="data row12 col6" >0.8638</td>
      <td id="T_b169b_row12_col7" class="data row12 col7" >0.7159</td>
      <td id="T_b169b_row12_col8" class="data row12 col8" >ok but below stronger models</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_b169b_row13_col0" class="data row13 col0" >2</td>
      <td id="T_b169b_row13_col1" class="data row13 col1" >embeddings tuned</td>
      <td id="T_b169b_row13_col2" class="data row13 col2" >svm linear tuned</td>
      <td id="T_b169b_row13_col3" class="data row13 col3" >0.7562</td>
      <td id="T_b169b_row13_col4" class="data row13 col4" >0.8297</td>
      <td id="T_b169b_row13_col5" class="data row13 col5" >0.7774</td>
      <td id="T_b169b_row13_col6" class="data row13 col6" >0.8894</td>
      <td id="T_b169b_row13_col7" class="data row13 col7" >0.7643</td>
      <td id="T_b169b_row13_col8" class="data row13 col8" >tiny tuning effect</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_b169b_row14_col0" class="data row14 col0" >2</td>
      <td id="T_b169b_row14_col1" class="data row14 col1" >embeddings tuned</td>
      <td id="T_b169b_row14_col2" class="data row14 col2" >random forest tuned</td>
      <td id="T_b169b_row14_col3" class="data row14 col3" >0.7338</td>
      <td id="T_b169b_row14_col4" class="data row14 col4" >0.8245</td>
      <td id="T_b169b_row14_col5" class="data row14 col5" >0.7364</td>
      <td id="T_b169b_row14_col6" class="data row14 col6" >0.9365</td>
      <td id="T_b169b_row14_col7" class="data row14 col7" >0.7725</td>
      <td id="T_b169b_row14_col8" class="data row14 col8" >strong recall gain</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_b169b_row15_col0" class="data row15 col0" >2</td>
      <td id="T_b169b_row15_col1" class="data row15 col1" >embeddings tuned</td>
      <td id="T_b169b_row15_col2" class="data row15 col2" >stacking ensemble</td>
      <td id="T_b169b_row15_col3" class="data row15 col3" >0.7529</td>
      <td id="T_b169b_row15_col4" class="data row15 col4" >0.8242</td>
      <td id="T_b169b_row15_col5" class="data row15 col5" >0.7847</td>
      <td id="T_b169b_row15_col6" class="data row15 col6" >0.8680</td>
      <td id="T_b169b_row15_col7" class="data row15 col7" >0.7561</td>
      <td id="T_b169b_row15_col8" class="data row15 col8" >strong ensemble</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_b169b_row16_col0" class="data row16 col0" >2</td>
      <td id="T_b169b_row16_col1" class="data row16 col1" >embeddings tuned</td>
      <td id="T_b169b_row16_col2" class="data row16 col2" >logistic regression tuned</td>
      <td id="T_b169b_row16_col3" class="data row16 col3" >0.7414</td>
      <td id="T_b169b_row16_col4" class="data row16 col4" >0.8165</td>
      <td id="T_b169b_row16_col5" class="data row16 col5" >0.7759</td>
      <td id="T_b169b_row16_col6" class="data row16 col6" >0.8616</td>
      <td id="T_b169b_row16_col7" class="data row16 col7" >0.7675</td>
      <td id="T_b169b_row16_col8" class="data row16 col8" >very small gain</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_b169b_row17_col0" class="data row17 col0" >2</td>
      <td id="T_b169b_row17_col1" class="data row17 col1" >embeddings tuned</td>
      <td id="T_b169b_row17_col2" class="data row17 col2" >svm rbf tuned</td>
      <td id="T_b169b_row17_col3" class="data row17 col3" >0.6676</td>
      <td id="T_b169b_row17_col4" class="data row17 col4" >0.8007</td>
      <td id="T_b169b_row17_col5" class="data row17 col5" >0.6676</td>
      <td id="T_b169b_row17_col6" class="data row17 col6" >1.0000</td>
      <td id="T_b169b_row17_col7" class="data row17 col7" >0.7660</td>
      <td id="T_b169b_row17_col8" class="data row17 col8" >collapses</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_b169b_row18_col0" class="data row18 col0" >2</td>
      <td id="T_b169b_row18_col1" class="data row18 col1" >embeddings tuned</td>
      <td id="T_b169b_row18_col2" class="data row18 col2" >knn tuned</td>
      <td id="T_b169b_row18_col3" class="data row18 col3" >0.6948</td>
      <td id="T_b169b_row18_col4" class="data row18 col4" >0.7980</td>
      <td id="T_b169b_row18_col5" class="data row18 col5" >0.7149</td>
      <td id="T_b169b_row18_col6" class="data row18 col6" >0.9030</td>
      <td id="T_b169b_row18_col7" class="data row18 col7" >0.7190</td>
      <td id="T_b169b_row18_col8" class="data row18 col8" >higher recall, unstable</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row19" class="row_heading level0 row19" >19</th>
      <td id="T_b169b_row19_col0" class="data row19 col0" >3</td>
      <td id="T_b169b_row19_col1" class="data row19 col1" >pca</td>
      <td id="T_b169b_row19_col2" class="data row19 col2" >random forest pca</td>
      <td id="T_b169b_row19_col3" class="data row19 col3" >0.7362</td>
      <td id="T_b169b_row19_col4" class="data row19 col4" >0.8079</td>
      <td id="T_b169b_row19_col5" class="data row19 col5" >0.7861</td>
      <td id="T_b169b_row19_col6" class="data row19 col6" >0.8310</td>
      <td id="T_b169b_row19_col7" class="data row19 col7" >0.7782</td>
      <td id="T_b169b_row19_col8" class="data row19 col8" >good balance</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row20" class="row_heading level0 row20" >20</th>
      <td id="T_b169b_row20_col0" class="data row20 col0" >3</td>
      <td id="T_b169b_row20_col1" class="data row20 col1" >pca</td>
      <td id="T_b169b_row20_col2" class="data row20 col2" >knn pca</td>
      <td id="T_b169b_row20_col3" class="data row20 col3" >0.7095</td>
      <td id="T_b169b_row20_col4" class="data row20 col4" >0.7988</td>
      <td id="T_b169b_row20_col5" class="data row20 col5" >0.7429</td>
      <td id="T_b169b_row20_col6" class="data row20 col6" >0.8638</td>
      <td id="T_b169b_row20_col7" class="data row20 col7" >0.7159</td>
      <td id="T_b169b_row20_col8" class="data row20 col8" >similar behaviour</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row21" class="row_heading level0 row21" >21</th>
      <td id="T_b169b_row21_col0" class="data row21 col0" >3</td>
      <td id="T_b169b_row21_col1" class="data row21 col1" >pca</td>
      <td id="T_b169b_row21_col2" class="data row21 col2" >svm linear pca</td>
      <td id="T_b169b_row21_col3" class="data row21 col3" >0.6914</td>
      <td id="T_b169b_row21_col4" class="data row21 col4" >0.7503</td>
      <td id="T_b169b_row21_col5" class="data row21 col5" >0.8157</td>
      <td id="T_b169b_row21_col6" class="data row21 col6" >0.6947</td>
      <td id="T_b169b_row21_col7" class="data row21 col7" >0.7623</td>
      <td id="T_b169b_row21_col8" class="data row21 col8" >balanced but weak</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row22" class="row_heading level0 row22" >22</th>
      <td id="T_b169b_row22_col0" class="data row22 col0" >3</td>
      <td id="T_b169b_row22_col1" class="data row22 col1" >pca</td>
      <td id="T_b169b_row22_col2" class="data row22 col2" >svm rbf pca</td>
      <td id="T_b169b_row22_col3" class="data row22 col3" >0.6924</td>
      <td id="T_b169b_row22_col4" class="data row22 col4" >0.7492</td>
      <td id="T_b169b_row22_col5" class="data row22 col5" >0.8219</td>
      <td id="T_b169b_row22_col6" class="data row22 col6" >0.6883</td>
      <td id="T_b169b_row22_col7" class="data row22 col7" >0.7650</td>
      <td id="T_b169b_row22_col8" class="data row22 col8" >ok but not strong</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row23" class="row_heading level0 row23" >23</th>
      <td id="T_b169b_row23_col0" class="data row23 col0" >3</td>
      <td id="T_b169b_row23_col1" class="data row23 col1" >pca</td>
      <td id="T_b169b_row23_col2" class="data row23 col2" >logistic regression pca</td>
      <td id="T_b169b_row23_col3" class="data row23 col3" >0.6814</td>
      <td id="T_b169b_row23_col4" class="data row23 col4" >0.7399</td>
      <td id="T_b169b_row23_col5" class="data row23 col5" >0.8130</td>
      <td id="T_b169b_row23_col6" class="data row23 col6" >0.6790</td>
      <td id="T_b169b_row23_col7" class="data row23 col7" >0.7681</td>
      <td id="T_b169b_row23_col8" class="data row23 col8" >signal reduced</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row24" class="row_heading level0 row24" >24</th>
      <td id="T_b169b_row24_col0" class="data row24 col0" >4</td>
      <td id="T_b169b_row24_col1" class="data row24 col1" >pca tuned</td>
      <td id="T_b169b_row24_col2" class="data row24 col2" >random forest pca tuned</td>
      <td id="T_b169b_row24_col3" class="data row24 col3" >0.7243</td>
      <td id="T_b169b_row24_col4" class="data row24 col4" >0.8266</td>
      <td id="T_b169b_row24_col5" class="data row24 col5" >0.7124</td>
      <td id="T_b169b_row24_col6" class="data row24 col6" >0.9843</td>
      <td id="T_b169b_row24_col7" class="data row24 col7" >0.7744</td>
      <td id="T_b169b_row24_col8" class="data row24 col8" >recall high, precision low</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row25" class="row_heading level0 row25" >25</th>
      <td id="T_b169b_row25_col0" class="data row25 col0" >4</td>
      <td id="T_b169b_row25_col1" class="data row25 col1" >pca tuned</td>
      <td id="T_b169b_row25_col2" class="data row25 col2" >logistic regression pca tuned</td>
      <td id="T_b169b_row25_col3" class="data row25 col3" >0.7410</td>
      <td id="T_b169b_row25_col4" class="data row25 col4" >0.8160</td>
      <td id="T_b169b_row25_col5" class="data row25 col5" >0.7761</td>
      <td id="T_b169b_row25_col6" class="data row25 col6" >0.8602</td>
      <td id="T_b169b_row25_col7" class="data row25 col7" >0.7675</td>
      <td id="T_b169b_row25_col8" class="data row25 col8" >slight gain</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row26" class="row_heading level0 row26" >26</th>
      <td id="T_b169b_row26_col0" class="data row26 col0" >4</td>
      <td id="T_b169b_row26_col1" class="data row26 col1" >pca tuned</td>
      <td id="T_b169b_row26_col2" class="data row26 col2" >knn pca tuned</td>
      <td id="T_b169b_row26_col3" class="data row26 col3" >0.7238</td>
      <td id="T_b169b_row26_col4" class="data row26 col4" >0.8153</td>
      <td id="T_b169b_row26_col5" class="data row26 col5" >0.7365</td>
      <td id="T_b169b_row26_col6" class="data row26 col6" >0.9130</td>
      <td id="T_b169b_row26_col7" class="data row26 col7" >0.7169</td>
      <td id="T_b169b_row26_col8" class="data row26 col8" >better recall</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row27" class="row_heading level0 row27" >27</th>
      <td id="T_b169b_row27_col0" class="data row27 col0" >4</td>
      <td id="T_b169b_row27_col1" class="data row27 col1" >pca tuned</td>
      <td id="T_b169b_row27_col2" class="data row27 col2" >svm rbf pca tuned</td>
      <td id="T_b169b_row27_col3" class="data row27 col3" >0.6681</td>
      <td id="T_b169b_row27_col4" class="data row27 col4" >0.8006</td>
      <td id="T_b169b_row27_col5" class="data row27 col5" >0.6684</td>
      <td id="T_b169b_row27_col6" class="data row27 col6" >0.9979</td>
      <td id="T_b169b_row27_col7" class="data row27 col7" >0.7660</td>
      <td id="T_b169b_row27_col8" class="data row27 col8" >collapse</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row28" class="row_heading level0 row28" >28</th>
      <td id="T_b169b_row28_col0" class="data row28 col0" >4</td>
      <td id="T_b169b_row28_col1" class="data row28 col1" >pca tuned</td>
      <td id="T_b169b_row28_col2" class="data row28 col2" >svm linear pca tuned</td>
      <td id="T_b169b_row28_col3" class="data row28 col3" >0.6938</td>
      <td id="T_b169b_row28_col4" class="data row28 col4" >0.7524</td>
      <td id="T_b169b_row28_col5" class="data row28 col5" >0.8176</td>
      <td id="T_b169b_row28_col6" class="data row28 col6" >0.6969</td>
      <td id="T_b169b_row28_col7" class="data row28 col7" >0.7636</td>
      <td id="T_b169b_row28_col8" class="data row28 col8" >small gain</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row29" class="row_heading level0 row29" >29</th>
      <td id="T_b169b_row29_col0" class="data row29 col0" >5</td>
      <td id="T_b169b_row29_col1" class="data row29 col1" >xgboost</td>
      <td id="T_b169b_row29_col2" class="data row29 col2" >xgboost pca</td>
      <td id="T_b169b_row29_col3" class="data row29 col3" >0.7481</td>
      <td id="T_b169b_row29_col4" class="data row29 col4" >0.8210</td>
      <td id="T_b169b_row29_col5" class="data row29 col5" >0.7811</td>
      <td id="T_b169b_row29_col6" class="data row29 col6" >0.8652</td>
      <td id="T_b169b_row29_col7" class="data row29 col7" >0.7795</td>
      <td id="T_b169b_row29_col8" class="data row29 col8" >still strong</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row30" class="row_heading level0 row30" >30</th>
      <td id="T_b169b_row30_col0" class="data row30 col0" >5</td>
      <td id="T_b169b_row30_col1" class="data row30 col1" >xgboost</td>
      <td id="T_b169b_row30_col2" class="data row30 col2" >xgboost</td>
      <td id="T_b169b_row30_col3" class="data row30 col3" >0.7443</td>
      <td id="T_b169b_row30_col4" class="data row30 col4" >0.8203</td>
      <td id="T_b169b_row30_col5" class="data row30 col5" >0.7725</td>
      <td id="T_b169b_row30_col6" class="data row30 col6" >0.8745</td>
      <td id="T_b169b_row30_col7" class="data row30 col7" >0.7862</td>
      <td id="T_b169b_row30_col8" class="data row30 col8" >strong model</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row31" class="row_heading level0 row31" >31</th>
      <td id="T_b169b_row31_col0" class="data row31 col0" >6</td>
      <td id="T_b169b_row31_col1" class="data row31 col1" >xgboost tuned</td>
      <td id="T_b169b_row31_col2" class="data row31 col2" >xgboost tuned</td>
      <td id="T_b169b_row31_col3" class="data row31 col3" >0.7524</td>
      <td id="T_b169b_row31_col4" class="data row31 col4" >0.8344</td>
      <td id="T_b169b_row31_col5" class="data row31 col5" >0.7537</td>
      <td id="T_b169b_row31_col6" class="data row31 col6" >0.9344</td>
      <td id="T_b169b_row31_col7" class="data row31 col7" >0.7883</td>
      <td id="T_b169b_row31_col8" class="data row31 col8" >best model</td>
    </tr>
    <tr>
      <th id="T_b169b_level0_row32" class="row_heading level0 row32" >32</th>
      <td id="T_b169b_row32_col0" class="data row32 col0" >6</td>
      <td id="T_b169b_row32_col1" class="data row32 col1" >xgboost tuned</td>
      <td id="T_b169b_row32_col2" class="data row32 col2" >xgboost pca tuned</td>
      <td id="T_b169b_row32_col3" class="data row32 col3" >0.7543</td>
      <td id="T_b169b_row32_col4" class="data row32 col4" >0.8267</td>
      <td id="T_b169b_row32_col5" class="data row32 col5" >0.7811</td>
      <td id="T_b169b_row32_col6" class="data row32 col6" >0.8780</td>
      <td id="T_b169b_row32_col7" class="data row32 col7" >0.7689</td>
      <td id="T_b169b_row32_col8" class="data row32 col8" >slight improvement</td>
    </tr>
  </tbody>
</table>
